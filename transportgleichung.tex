Wir betrachten die Differentialgleichung der eindimensionalen Advektion
\begin{align}\label{eq:adv:pde}
\partial_t u(t, x) + \partial_x u(t, x) = 0, \quad u(0, x) = U(x).
\end{align}
Auf diese partielle Differentialgleichung wenden wir das Upwindverfahren mit dem Gitter $G_h(n,i) = (t_n, x_i) = h \cdot (\lambda n, i)$ an.
Wenn wir also von Punkten $(t_n, x_i)$ in der Raumzeit sprechen, so sind diese eigentlich noch von Gitterweite $h$ abhängig. 
Dieses Gitter ist nicht quadratisch, falls $\lambda \neq 1$ gilt und das Verfahren ist durch die Gleichung
\begin{align}\label{eq:adv:scheme_rechnung}
\frac {v^{n+1}_i - v^n_i} {\lambda h} + \frac {v^n_i - v^n_{i-1}} h = 0
\end{align}
bzw. in der Praxis durch
\begin{align}\label{eq:adv:scheme}
v^{n+1}_i = v^n_i - \lambda (v^n_i - v^n_{i-1})
\end{align}
bestimmt.
Es ist bereits bekannt, dass das Verfahren f"ur $\lambda \leq 1$ stabil und f"ur $\lambda = 1$ sogar exakt ist.
Wir versuchen hier den instabilen Fall $\lambda > 1$ besser zu verstehen und nehmen in diesem Kapitel daher $\lambda = 1 + \eta$ f"ur ein $\eta > 0$ an.

\section{Die analytische Lösung}

\section{Ein erster regulärer Ansatz}

\section{Ein Beispiel für instabiles Verhalten}\label{sec:transport:beispiel}

Wir schauen uns die Ergebnisse des Verfahrens für die Anfangswerte $U(x) = \sin(\pi x)$ und $\lambda = 1 + \eta$ für verschiedene $\eta$ an.
Wir haben die Beispiele durch das Skript \ref{appendix:transport:beispiel} in \emph{GNU Octave} umgesetzt und untersuchen, was für verschiede $\eta$ und kleine $h$ passiert.
Das gibt uns erste Hinweise darauf, was wir in unseren Untersuchungen zu erwarten haben.

\begin{figure}
\centering
\begin{tikzpicture}[scale=0.58]
\begin{axis}[
    height = 0.6\textwidth,
    width = 0.6\textwidth,
    title = {$\eta = 0.1, h = 0.01, n = 198$},
    xtick = {-2,-1,...,2},
    grid  = both,
]
\addplot[myblue] table [y index= 2] {data/V_sinus_eta_0.100_h_0.001.dat};
\end{axis}
\end{tikzpicture}
\begin{tikzpicture}[scale=0.58]
\begin{axis}[
    height = 0.6\textwidth,
    width = 0.6\textwidth,
    title = {$\eta = 0.1, h = 0.001, n = 198$},
    xtick = {-2,-1,...,2},
    grid  = both,
]
\addplot[myblue] table [y index= 2] {data/V_sinus_eta_0.100_h_0.001.dat};
\end{axis}
\end{tikzpicture}
\begin{tikzpicture}[scale=0.58]
\begin{axis}[
    height = 0.6\textwidth,
    width = 0.6\textwidth,
    title = {$\eta = 0.05, h = 0.001, n = 378$},
    xtick = {-2,-1,...,2},
    grid  = both,
]
\addplot[myblue] table [y index= 2] {data/V_sinus_eta_0.050_h_0.001.dat};
\end{axis}
\end{tikzpicture}
\caption{Vergleich des instabilen Verhaltens für verschiedene $\eta$ und $h$}
\label{fig:transport:beispiel}
\end{figure}


Vergleicht man nun die Plots in Abbildung~\ref{fig:transport:beispiel} untereinander, so erkennt man, dass die maximale Amplitude der Oszillation scheinbar unabh"angig von $h$ mit der Anzahl der Iterationen $n$ w"achst.
Verringert man jedoch den Wert für $\eta$, so ändert sich auch die Rate, um die die Amplitude wächst.
Wir werden dieses Verhalten in unseren Approximationen wiederfinden und geben ferner Abschätzungen für das Wachstum der Amplitude an.
Die konkreten Iterationen $n$ für die Plots in den Abbildungen wurden mit Hilfe der Abschätzung $(1 + 2 \eta)^n$ aus dem Unterkapitel \ref{sec:transport:osz} ausgewählt.


\section {Allgemeine diskrete Ansätze auf Gitterniveau} \label{sec:transport:diskret}

Wir führen hier Raumzeit-Koordinaten auf einer kurzen Skala ein.
Genau genommen machen wir unsere Ansatzfunktionen zusätzlich von den diskreten Gitterkoordinaten $(n,i)$ abhängig.
Es gilt zwar $n = \frac {t_n} {\lambda h}$ und $i = \frac {x_i}{h}$, jedoch soll unsere Annahme sein, dass der Ansatz unstetig in $n$ und $i$ ist.
Möchte man jedoch für $h \to 0$ einen Punkt $(t,x)$ in der Raumzeit approximieren, so gilt immer $n,i \to \infty$ und dies könnte uns zusätzliche Bedingungen liefern.
% Da unsere Gleichung linear ist, nehmen wir an, dass wir die Gitterfunktion als Summe einer Lösung und kleinen Oszillationen schreiben können.
Unser Ansatz lautet dieses mal
\begin{align}\label{eq:transport:diskret:ansatz}
v^n_i = u_0(n, i, t_n, x_i) + h u_1(n, i, t_n, x_i) + h^2 u_2(n, i, t_n, x_i) + o(h^2).
\end{align}
Zunächst fällt auf, dass wir im Gegensatz zum regulärem Ansatz hier Terme bis zur Ordnung $O(h^2)$ entwickeln.
Durch die kurze Zeit- und Ortskala wirken Terme in einer Ordnung niedriger als zuvor.
Daher werden Terme von $u_2$ Gleichungen in $O(h)$ beeinflussen und müssen betrachtet werden.
Im Anhang \ref{appendix:diskret:summanden} haben wir die einzelnen Summanden von \eqref{eq:adv:scheme} ausgerechnet.
Setzt man diese, \eqref{eq:transport:diskret:diff1} und \eqref{eq:transport:diskret:diff2}, nun in \eqref{eq:adv:scheme} ein, liefert uns das die Gleichungen

\vspace{0.4cm}
\noindent \emph{in der Ordnung $O(1)$:}
\begin{align}\label{eq:transport:diskret:o1}
u_0(n+1, i, t_n, x_i) - u_0(n, i, t_n, x_i)
+ \lambda \bigl(u_0(n, i, t_n, x_i) - u_0(n, i-1, t_n, x_i) \bigr) = 0
\end{align}
\vspace{0.4cm}
\noindent \emph{in der Ordnung $O(h)$:}
\begin{align}\label{eq:transport:diskret:oh}
\lambda \bigl( \partial_t u_0(n+1, i, t_n, x_i) + \partial_x u_0(n, i-1, t_n, x_i) \bigr) =
\begin{split}
&- \bigl( u_1(n+1, i, t_n, x_i) - u_1(n, i, t_n, x_i) \bigr)\\
&- \lambda \bigl(u_1(n, i, t_n, x_i) - u_1(n, i-1, t_n, x_i) \bigr)
\end{split}
\end{align}
\vspace{0.4cm}
\noindent \emph{in der Ordnung $O(h^2)$:}
% {\small
\begin{align}\label{eq:transport:diskret:oh2}
\lambda \bigl( \partial_t u_1(n+1, i, t_n, x_i) + \partial_x u_1(n, i-1, t_n, x_i) \bigr) =
\begin{split}
&\frac {\lambda}{2} \partial^2_x u_0(n, i-1, t_n, x_i) - \frac{\lambda^2}{2} \partial^2_t u_0(n+1, i, t_n, x_i)\\
&- \bigl( u_2(n+1, i, t_n, x_i) - u_2(n, i, t_n, x_i) \bigr)\\
&- \lambda \bigl(u_2(n, i, t_n, x_i) - u_2(n, i-1, t_n, x_i) \bigr)
\end{split}
\end{align}
% }
\vspace{0.4cm}
\noindent \emph{in der Ordnung $O(h^3)$:}
\begin{align}\label{eq:transport:diskret:oh3}
\begin{split}
\lambda \bigl(\partial_t u_2(n+1, i, t_n, x_i)\qquad\\
\quad + \partial_x u_2(n, i-1, t_n, x_i) \bigr)
\end{split}
&= \begin{split}
- \left(\frac {\lambda}{6} \partial^3_x u_0(n, i-1, t_n, x_i) + \frac{\lambda^3}{6} \partial^3_t u_0(n+1, i, t_n, x_i)\right)\\
- \left(\frac {\lambda}{2} \partial^2_x u_1(n, i-1, t_n, x_i) + \frac{\lambda^2}{2} \partial^2_t u_1(n+1, i, t_n, x_i)\right)
\end{split}
\end{align}

\vspace{0.4cm}
\noindent \emph{Mit den Anfangsbedingungen:}
\begin{align}\label{eq:transport:diskret:anfangsbedinungen}
u_0(0, i, 0, x_i) = \rd{U(x_i)}, \quad u_1(0, i, 0, x_i) = 0 \quad \text{und} \quad u_2(0, i, 0, x_i) = 0 \qquad \forall i \in \Z.
\end{align}

Diese Gleichungen gelten nun für alle $h > 0$ und alle $n, i \in \N$.
Noch gelingt es uns nicht, aus diesen Bedinungen eine eindeutige Lösung für unsere Ansatzfunktionen $u_0, u_1$ und $u_2$ zu bestimmen.
Daher folgt im nächstem Kapitel ein konkreterer Produktansatz.
Trotzdem beweisen wir hier noch zwei Lemmata, um besser zu verstehen wie man von Bedingungen auf dem Gitter auf Bedingungen im Raum schließen kann.

\begin{lemma}[Konstanz für eine Dimension] \label{lemma:transport:diskret:konstant1}
Sei $f\colon \N \times \R^+_0 \to \R$ eine Abbildung.
Sei weiter $G_h \subset \R^+_0$ ein äquidistantes Gitter mit $G_h(n) = t^h_n = n h$, für $n \in \N$.
Wenn ein $F\colon \Rp \to \R$ für alle $h > 0$ und somit alle Gitter $G_h$ mit
\begin{align}\label{eq:lemma:const1d:voraussetzung}
F(t^h_n) = f(n, t^h_n) \qquad \text{für alle $n \in \N$}
\end{align}
existiert, dann gilt für alle $t \in \Rp$ und alle $n \in \N$
\[ F(t) = f(n, t). \]
\end{lemma}
Der Beweis dieses Lemmas ist denkbar einfach. Die Existenz eines solchen $F$ ist wie eine Gleichmäßigkeitsbedingung über alle möglichen Gitter.
Zu gegebenen $t \in \Rp$ wähle man sich einfach die richtige Gitterweite $h > 0$.
\begin{proof}
Sei $F\colon \Rp \to \R$ gegeben und sei $t \in \Rp$ beliebig.
Wähle $h = \frac{t}{n}$, dann gilt $t^h_n = nh = n \frac{t}{n} = t$.
Da \eqref{eq:lemma:const1d:voraussetzung} für alle $h > 0$ gilt, folgt hiermit 
\[ F(t) = F(t^h_n) = f(n, t^h_n) = f(n, t). \qedhere \]
\end{proof}

Das Lemma~\ref{lemma:transport:diskret:konstant1} bedeutet, dass $f$, oder die Folge $f_n$, in solchen Fällen unabhängig von, bzw. konstant in $n \in \N$ ist.
Wir wollen dies auf unseren Fall übertragen und beweisen nun das zweidimensionale Analogon, 

\begin{lemma}[Punktweise Kovergenz in der Raumzeit]\label{lemma:transport:diskret:konvergenz_gitter}
Sei $f\colon (\N \times \Z) \times (\Rp \times \R) \to \R$ eine Abbildung, so dass $f(n,i,\pkt,\pkt)$ für alle $n \in \N$ und $i \in \Z$ differenzierbar ist.
Sei weiter\, $G_h \subset \Rp \times \R$ ein äquidistantes Gitter mit\, $G_h(n,i) = (t^h_n, x^h_i) = h \cdot (\lambda n, i)$, für $n \in \N$.
Wenn ein differenzierbares $F\colon \Rp \times \R \to \R$ für alle $h > 0$ und somit alle Gitter $G_h$ mit
\begin{align}\label{eq:lemma:diag:voraussetzung}
F(t^h_n, x^h_i) = f(n, i, t^h_n, x^h_i) \qquad \text{für alle $(n,i) \in \N \times \Z$}
\end{align}
existiert, dann gilt für alle $(t, x) \in \Rp \times \R$, dass für alle $n \in \N$ ein $i(n) \in \Z$ existiert mit
\begin{align}\label{eq:lemma:diag:aussage}
\abs{F(t, x) - f(n, i(n), t, x)} \leq \frac {t}{\lambda n} \Bigl(\bigl\lvert f_x(n, i(n), t, x) \bigr\rvert + \bigl\lvert F_x(t, x) \bigr\rvert \Bigr)
\end{align}
\end{lemma}
\begin{proof}
Ähnlich wie in Lemma~\ref{lemma:transport:diskret:konstant1} setzen wir $h = \frac {t}{\lambda n}$.
Dann gilt $t_n = \lambda n h = t$ und $x_i = i h$ für $i \in \Z$.
O.\,B.\,d.\,A. gelte $x > 0$.
Dann gibt es ein kleinstes $i(n) = i \in \N$, für das $x_{i-1} < x \leq x_i$ gilt.
Dies impliziert $x_i - x < h$ und wegen $t_n = t$ folgt auch
\[ \norm{(t,x) - (t_n, x_i)} = \abs{x - x_i} < h. \]
Weil $f$ und $F$ differenzierbar in $x$ sind, folgt somit
\[ \abs{f(n, i, t_n, x_i) - f(n, i, t, x)} = \abs{(x_i - x) f_x(n, i, t, x) + o(h)} \leq h \abs{f_x(n, i, t, x)} + o(h) \]
und
\[ \abs{F(t_n, x_i) - F(t, x)} = \abs{(x_i - x) F_x(t, x) + o(h)} \leq h \abs{F_x(t, x)} + o(h). \]
Zusammen ergibt das
{\small
\begin{align*}
\abs{F(t,x) - f(n, i, t, x)} &\leq \abs{F(t, x) - F(t_n, x_i)} + \underbrace{\abs{F(t_n, x_i) - f(n, i, t_n, x_i)}}_{= 0} + \abs{f(n,i, t, x) - f(n, i, t_n, x_i)}\\
&\leq h \Bigl(\bigl\lvert f_x(n, i, t, x) \bigr\rvert + \bigl\lvert F_x(t, x) \bigr\rvert \Bigr)\\
&= \frac {t}{\lambda n} \Bigl(\bigl\lvert f_x(n, i, t, x) \bigr\rvert + \bigl\lvert F_x(t, x) \bigr\rvert \Bigr). \qedhere
\end{align*}
}
\end{proof}
Sollte das Lemma \ref{lemma:transport:diskret:konvergenz_gitter} exakt sein, so zeigt uns das, dass wir gleichmäßige Schranken von $f(n, i, \pkt, \pkt)$ benötigen, um von Aussagen auf Gitterebene auf Aussagen über alle Raumzeitpunkte zu schließen.
Selbst dann, wenn man das Lemma dahingehend abschwächt, dass man nur die gleichmäßige Stetigkeit in $n$ und $i$ braucht.
Und diese Bedingung tretet schon ein, ohne dass wir die Sublinear-Growth Bedingung überhaupt benutzt haben.


\section {Ein Ansatz mit alternierenden Gittervorzeichen}\label{sec:transport:osz}

Hier präzisieren wir unseren Ansatz \eqref{eq:transport:diskret:ansatz} aus dem letztem Unterkapitel. % \ref{sec:transport:diskret}.
Sei $\eps_M > 0$ die Maschinengenauigkeit.
Diese Größe ist von System zu System unterschiedlich und ist in der Regel in der Größenordnung von etwa $10^{-16}$ groß.
Die Anfangsbedingung für $u_0$ in \eqref{eq:transport:diskret:anfangsbedinungen} lautet
\begin{align*}
u_0(0, i, 0, x_i) &= \rd{U(x_i)} = U(x_i) - \underbrace{\left( U(x_i) - \rd{U(x_i)} \right)}_{=: \Delta_{\eps_M} U(x_i)}\\
&= U(x_i) - \Delta_{\eps_M} U(x_i),
\end{align*}
Das Vorzeichen der Rundungsfehler kann nach der ersten Iteration jedoch von Gitterzelle zur Gitterzelle schon anders sein!
Deshalb motiviert das hier den Ansatz, dass Oszillationen im Raum und auf Gitterniveau vorhanden sind und wir untersuchen, wie sich die Amplitude in der Zeit ausbreitet.
Weil wir in \eqref{eq:adv:pde} eine lineare Differentialgleichung betrachten, vermuten wir, dass man $u_k$ für $k = 0,1,2$ und alle Iterationen $n \in \N$ als Summe einer glatten und einer unstetigen, hochfrequenten Funktion schreiben kann.
Daher wählen wir für $u_0, u_1$ und $u_2$ aus \eqref{eq:transport:diskret:ansatz} nun konkreter 
\begin{align*}
u_k(n, i, t, x) &= w_k(t, x) + (-1)^i \Omega(n) z_k(t, x), \qquad \text{für $k = 0,1,2$}
\end{align*}
für glatte Funktionen $w_k, z_k$, $\Omega(0) = 1$ und
\begin{align}\label{eq:transport:osz:anfangsbedinungen}
\begin{split}
w_0(0, x_i) &= U(x_i),\\
w_1(0, x_i) &= 0,\\
w_2(0, x_i) &= 0,
\end{split}&
\begin{split}
z_0(0, x_i) &= V(x_i),\\
z_1(0, x_i) &= 0,\\
z_2(0, x_i) &= 0.
\end{split}
\end{align}
Wobei $U$ und $V$ derart sind, dass alle nötigen Regularitätsbedingungen für die kommenden Betachtungen erfüllt seien sollen.
Setzt man dies in die vorherigen Rechnungen ein, so erhält man anstelle von Gleichung \eqref{eq:transport:diskret:o1}

\vspace{0.4cm}
\noindent \emph{in der Ordnung $O(1)$:}
\begin{align}\label{eq:transport:osz:o1} % \nonumber
% \begin{split}
- (-1)^i z_0(t_n, x_i) \Bigl[ \Omega(n+1) - ( 1 - 2 \lambda ) \Omega(n) \Bigr] = 0.
\end{align}

Da diese Gleichung für alle Gitterpunkte $(n,i)$ gilt und die Funktion $F(t,x) = 0$ glatt ist, können wir unter der Annahme, dass $z_0 \neq 0$ gilt, Lemma \ref{lemma:transport:diskret:konvergenz_gitter} benutzen.
\begin{satz}\label{satz:omega_n}
Es gilt
\[ \Omega(n) = (1 - 2 \lambda)^n = (-1)^n (1 + 2 \eta)^n. \]
\end{satz}
\begin{proof}
Weil $z_0 \neq 0$ gilt, existiert ein Punkt $(t,x) \in \Rp \times \R$ mit $z_0(t,x) \neq 0$.
Nach Lemma \ref{lemma:transport:diskret:konvergenz_gitter} existiert für jedes $n \in \N$ ein $i \in \Z$ mit
\[  \abs{(-1)^i z_0(t, x) \bigl( \Omega(n+1) - ( 1 - 2 \lambda ) \Omega(n) \bigr)} \leq \abs{(-1)^i \frac {t}{\lambda n} \partial_x z_0(t, x) \bigl( \Omega(n+1) - ( 1 - 2 \lambda ) \Omega(n) \bigr)}. \]
Angenommen es gelte $\Omega(n+1) - ( 1 - 2 \lambda ) \Omega(n) \neq 0$.
Hieraus folgt wiederum für alle $n \in \N$
\[ \abs{z_0(t, x)} \leq \frac {t}{\lambda n} \abs{\partial_x z_0(t,x)}, \]
was zu $z_0(t,x) = 0$ führt, ein Widerspruch zur Voraussetzung $z_0(t,x) \neq 0$.
Das impliziert $\Omega(n+1) - ( 1 - 2 \lambda ) \Omega(n) = 0$ für alle $n \in \N$ und mit $\Omega(0) = 1$ folgt die Behauptung.
\end{proof}

Setzt man Satz \ref{satz:omega_n} nun in den Ansatz ein, so fallen die Anteile von $u_2$ in der Gleichung \eqref{eq:transport:diskret:oh2} für diskrete Ansätze weg.
Daher reduziert sich mit $\lambda = 1 + \eta$ dieser Ansatz hier zu
\begin{align}\label{eq:transport:osz:ansatz}
v^n_i = w_0(t_n, x_i) + h  w_1(t_n, x_i) + (-1)^{i+n} (1 + 2 \eta)^n \bigl( z_0(t_n, x_i) + h z_1(t_n, x_i) \bigr) + o(h)
\end{align}
und sortiert man, wie im Anhang \ref{appendix:osz:sortiere_nach_frequenz} gezeigt, die Gleichungen \eqref{eq:transport:diskret:oh} und \eqref{eq:transport:diskret:oh2} nach stetigen und hochfrequentiellen Anteilen, so erhalten wir aufgrund der Glattheit der Abbildungen $w_k$ und $z_k$ die Gleichungen

\vspace{0.4cm}
\noindent \emph{in der Ordnung $O(h)$:}
\begin{align}
\partial_t w_0(t, x) + \partial_x w_0(t, x) = 0 \label{eq:transport:osz:oh_A}\\
\partial_t z_0(t, x) + \frac {1} {1 + 2\eta} \partial_x z_0(t, x) = 0 \label{eq:transport:osz:oh_B}
\end{align}
\vspace{0.4cm}
\noindent \emph{in der Ordnung $O(h^2)$:}
% {\small
\begin{align}\label{eq:transport:osz:oh2_A}
\partial_t w_1(t, x) + \partial_x w_1(t, x) &= - \frac {\eta}{2} \partial^2_x w_0(t, x)\\
\partial_t z_1(t, x) + \frac{1}{1 + 2 \eta} \partial_x z_1(t, x) &= \frac{\eta}{2 (1 + 2 \eta)^2} \partial^2_x z_0(t, x) \label{eq:transport:osz:oh2_B}
\end{align}

\noindent \emph{Mit den Anfangsbedingungen in \eqref{eq:transport:osz:anfangsbedinungen}}

\vspace{0.4cm}
Betrachtet man den Ansatz \eqref{eq:transport:osz:ansatz} nun genauer, so erkennt man, dass der Faktor $(1 + 2 \eta)^n$ für $\eta > 0$ und $n \to \infty$ unbeschränkt ist.
Das heißt, der Ansatz kann bestenfalls nur für feste $h > 0$ gelten und hilft, wenn überhaupt, zu verstehen, wie sich das Verfahren unter solchen Bedingungen und in endlich vielen Iterationen verhält.
In diesem Fall gibt es für jede Zeit $t > 0$ und zu jeder Schranke $X > 0$ ein $h > 0$, so dass $\abs{v^n_i} > X$ und $n \lambda h = t_n < t$ gilt.
Das heißt, dass es für $h \to 0$ gar kein Zeitinterval geben kann, in dem der Ansatz \eqref{eq:transport:osz:ansatz} konvergiert. 
Allerdings bedeutet das auch, dass wir im Gegensatz zum regulären Fall die Lösungen $w_k$
\begin{align}\label{eq:transport:osz:wk_loesungen}
w_0(t, x) &= U(x - t) \qquad \text{und}\\
w_1(t, x) &= - t \frac{\eta} 2 \partial^2_x U(x - t)
\end{align}
hinnehmen, da wir uns sowieso nicht wie z.\,B. für den Fall $\lambda < 1$ für das Langzeitverhalten der Lösung interessieren.

Der Faktor $\frac{\eta}{2 (1 + 2 \eta)^2}$ in Gleichung \eqref{eq:transport:osz:oh2_B} ist für $\eta > 0$ positiv!
Das heißt, dass sich $z_0$ diffusiv in der Zeit ausbreitet.
Wie die Autoren in \cite{Junk2004} kann man für diesen Fall eine langsame Zeitskala $\tau_n = h t_n$ für $z_0$ in den Ansatz einbauen.
Dann gilt
\begin{align*}
\partial_t z_0(t, \tau, x) + \frac {1} {1 + 2 \eta} \partial_x z_0(t, \tau, x) &= 0\\
\partial_t z_1(t, \tau, x) + \frac {1} {1 + 2 \eta} \partial_x z_1(t, \tau, x) &= \frac{\eta}{2 (1 + 2 \eta)^2} \partial^2_x z_0(t, \tau, x) - \partial_\tau z_0(t, \tau, x)\\
\end{align*}
und fordert, dass
\[ 
\partial_\tau z_0(t, \tau, x) = \frac{\eta}{2 (1 + 2 \eta)^2} \partial^2_x z_0(t, \tau, x) 
\]
gilt. Mit $z_1(0,0,x) = 0$ folgt also $z_1 = 0$ und
\begin{align*}
z_0(t, \tau, x) &= (V * G_\tau)\left(x - \frac{t}{1 + 2 \eta} \right) \\
G_\tau(y) &= \sqrt {\frac{1}{\tau} \frac {(1 + 2 \eta)^2}{2 \pi \eta}} \exp\left( - \frac{y^2}{\tau} \frac {(1 + 2 \eta)^2}{2 \pi \eta} \right)
\end{align*}
Wenn wir alle Ergebnisse zusammensetzen gelangen wir zu dem folgendem Ausdruck
\begin{align}\label{eq:transport:osz:loesung}
v^n_i = U(x_i - t_n) + (-1)^{i+n} (1+ 2 \eta)^n (V * G_{\tau_n})\left(x - \frac{t_n}{1 + 2 \eta} \right) - \frac{h\eta} 2 t_n \partial^2_x U(x_i - t_n) + o(h).
\end{align}
Wir nehmen für ein konkretes Beispiel die Startwerte $U(x) = \sin(\pi x)$ und $V(x) = \eps_M$.
Wenn wir das in \eqref{eq:transport:osz:loesung} einsetzen, so gilt zunächst für alle $x, \tau \in \R:$ $(V * G_\tau)(x) = \eps_M$ und es gilt $\partial^2_x U(x_i - t_n) = \pi^2 \sin\bigl(\pi (x_i - t_n)\bigr)$ für alle $(t_n, x_i) \in G_h$.
Ersetzt man ferner $t_n = n (1+\eta) h$ so erhält man insgesamt
\begin{align}
v^n_i = \sin\bigl(\pi (x_i - t_n) \bigr)\left( 1 + n \frac {\pi^2} 2 h^2 \eta (1 + \eta) \right)  + (-1)^{i+n} (1 + 2 \eta)^n \eps_M + o(h).
\end{align}
Damit ist dann die Fehlerabschätzung verbunden 
\begin{align}\label{eq:transport:osz:sinus_fehler}
\err^n &= \max_{i \in \Z} \abs{\sin\bigl(\pi (x_i - t_n) \bigr) - v^n_i} \nonumber \\
&= \max_{i \in \Z} \abs{\sin\bigl(\pi (x_i - t_n) \bigr) n \frac {\pi^2} 2 h^2 \eta (1 + \eta)  + (-1)^{i+n} (1 + 2 \eta)^n \eps_M + o(h)} \nonumber\\
&\leq \max_{i \in \Z} \abs{\sin\bigl(\pi (x_i - t_n) \bigr) n \frac {\pi^2} 2 h^2 \eta (1 + \eta)}  + \abs{(-1)^{i+n} (1 + 2 \eta)^n \eps_M} + o(h) \nonumber\\
&= (1 + 2 \eta)^n \eps_M + n \frac {\pi^2} 2 h^2 \eta (1 + \eta) + o(h)
\end{align}
\begin{figure}
\centering
\begin{tikzpicture}
\begin{semilogyaxis}[
    title={$\err^n = \max_{i \in \Z} \abs{\sin\bigl(\pi (x_i -t_n)\bigr) - v^n_i}$},
    xlabel={Iterationen $n$},
    ylabel={maximaler Fehler},
    legend entries={$\err^n \, \eta=0.01$,$\err^n \, \eta=0.05$,$\err^n \, \eta=0.1$,$(1+2 \eta)^n\eps_M + \frac{\pi^2}{2} n h^2 (1 + \eta) \eta$, $(1+2 \eta)^n\eps_M$},
    legend style={at={(1.8,1)}}
]
\addplot[myblue, line width={0.8}, mark=*] table {data/max_errors_eta_0.010_h_0.001.dat};
\addplot[dg, line width={0.8}, mark=*] table {data/max_errors_eta_0.050_h_0.001.dat};
\addplot[red, line width={0.8}, mark=*] table {data/max_errors_eta_0.100_h_0.001.dat};
\addplot[black, line width={0.3}, mark=x] table [y index={2}] {data/max_errors_eta_0.050_h_0.001.dat};
\addplot[mygray, line width={0.5}, dotted] table [y index={3}] {data/max_errors_eta_0.010_h_0.001.dat};
\addplot[mygray, line width={0.5}, dotted] table [y index={3}] {data/max_errors_eta_0.050_h_0.001.dat};
\addplot[mygray, line width={0.5}, dotted] table [y index={3}] {data/max_errors_eta_0.100_h_0.001.dat};
\addplot[black, line width={0.3}, mark=x] table [y index={2}] {data/max_errors_eta_0.010_h_0.001.dat};
\addplot[black, line width={0.3}, mark=x] table [y index={2}] {data/max_errors_eta_0.100_h_0.001.dat};
\end{semilogyaxis}
\end{tikzpicture}
\caption{Hier vergleichen wir die maximalen Fehler der numerischen Lösungen für die Startwerte $U(x) = sin(\pi x)$, $V(x) = \eps_M$ und $h = 10^{-3}$ für $\eta = 0.1, 0.05$ und $0.001$ zur echten Lösung $u(t,x) = sin(\pi(x - t))$ mit dem geschätztem Fehler $u(t_n, x_i) - v^n_i$ aus der asymptotischen Entwicklung in \eqref{eq:transport:osz:loesung}.}
\label{fig:transport:osz:max_error}
\end{figure}

In Abbildung \ref{fig:transport:osz:max_error} vergleichen wir den maximalen Fehler der Beispiele im Unterkapitel \ref{sec:transport:beispiel} mit dem Fehler des Ansatzes $v^n_i$ aus \eqref{eq:transport:osz:sinus_fehler}.
Dabei erkennt man, dass dieses Modell schon eine ganz gute Approximation für das Wachstum der Rundungsfehler für verschiedene $\eta > 0$ liefert.
Es bleibt trotzdem unbefriedigend, dass man über keine Konvergenz für $h \to 0$ im klassischen Sinne sprechen kann.
Für $h \to 0$ gilt stets $h \ll \eta$, was bedeutet, dass dieser Ansatz hier Aussagen für beliebig große $\eta$ trifft.
Darin liegen auch die Grenzen von \eqref{eq:transport:osz:loesung} begründet.
Dieses Problem gehen wir mit dem nächstem Unterkapitel an.

\section{Kleine Störungen der Courant-Friedrich-Lewy Bedingung}\label{sec:transport:kleineta}

$h \ll \eta$ führt fundamental zu dem Problem, dass kleine Rundungsfehler zu jeder noch so kleinen Zeit $t > 0$ beliebig groß werden und die richtige Lösung komplett überdecken.
Wir rechnen in der Praxis jedoch mit einem positvem $h > 0$, für das eventuell auch $h \sim \eta$ gelten kann.
Konkrete numerische Realisierungen existieren und entwickeln Oszillationen für feste $h$ zu positiven Zeiten $t > 0$.
Gerade für Probleme, bei denen numerische Daten nur in einem ``kurzem'' Zeitinterval unter instabilen Bedingungen gerechnet werden, könnte es also interessante Einblicke geben, das asymptotische Verhalten eines Verfahren für ``kleine'' Störungen der CFL Zahl zu kennen.
Der bisherige Ansatz hat dies ignoriert und obwohl Abbildung \ref{fig:transport:osz:max_error} zeigt, dass \eqref{eq:transport:osz:loesung} bereits gute Approximationen liefert, werden solche Überlegungen spätestens für die Advektion mit variabler Geschwindigkeit oder auch nichtlineare Probleme von Nöten sein.
Daher betrachten wir nun die Koppelung $\eta = h$ und setzen $\lambda = 1 + h$ in die Gleichungen ein \eqref{eq:transport:diskret:o1} bis \eqref{eq:transport:diskret:oh3} ein:

\vspace{0.4cm}
\noindent \emph{in der Ordnung $O(1)$:}
\begin{align}\label{eq:transport:kleineta:o1}
u_0(n+1, i, t_n, x_i) - u_0(n, i, t_n, x_i) + u_0(n, i, t_n, x_i) - u_0(n, i-1, t_n, x_i) = 0
\end{align}
\vspace{0.4cm}
\noindent \emph{in der Ordnung $O(h)$:}
\begin{align}\label{eq:transport:kleineta:oh}
\partial_t u_0(n+1, i, t_n, x_i) + \partial_x u_0(n, i-1, t_n, x_i) =
\begin{split}
&- \bigl( u_0(n, i, t_n, x_i) - u_0(n, i-1, t_n, x_i) \bigr)\\
&- \bigl( u_1(n+1, i, t_n, x_i) - u_1(n, i, t_n, x_i) \bigr)\\
&- \bigl( u_1(n, i, t_n, x_i) - u_1(n, i-1, t_n, x_i) \bigr)
\end{split}
\end{align}
\vspace{0.4cm}
\noindent \emph{in der Ordnung $O(h^2)$:}
% {\small
\begin{align}\label{eq:transport:kleineta:oh2}
\begin{split}
\partial_t u_1(n+1, i, t_n, x_i) + \partial_x u_1(n, i-1, t_n, x_i) +\\
\partial_t u_0(n+1, i, t_n, x_i) + \partial_x u_0(n, i-1, t_n, x_i)
\end{split}
&=
\begin{split}
&- \bigl( u_1(n, i, t_n, x_i) - u_1(n, i-1, t_n, x_i) \bigr)\\
&- \bigl( u_2(n+1, i, t_n, x_i) - u_2(n, i, t_n, x_i) \bigr)\\
&- \bigl( u_2(n, i, t_n, x_i) - u_2(n, i-1, t_n, x_i) \bigr)
\end{split}
\end{align}
% }
\vspace{0.4cm}
\noindent \emph{in der Ordnung $O(h^3)$:}
\begin{align}\label{eq:transport:kleineta:oh3}
\begin{split}
\partial_t u_2(n+1, i, t_n, x_i) + \partial_x u_2(n, i-1, t_n, x_i) +\\
\partial_t u_1(n+1, i, t_n, x_i) + \partial_x u_1(n, i-1, t_n, x_i)
\end{split}
&=
\begin{split}
&\left( \frac{1}{2} \partial^2_x  - \partial^2_t \right) u_0(n, i-1, t_n, x_i) \\
&- \bigl( u_2(n, i, t_n, x_i) - u_2(n, i-1, t_n, x_i) \bigr)
\end{split}
\end{align}
\emph{mit den Anfangsbedingungen}
\begin{align}\label{eq:transport:kleineta:anfangsbedinungen}
\begin{split}
w_0(0, x_i) &= U(x_i),\\
w_1(0, x_i) &= 0,\\
w_2(0, x_i) &= 0,
\end{split}&
\begin{split}
z_0(0, x_i) &= V(x_i),\\
z_1(0, x_i) &= 0,\\
z_2(0, x_i) &= 0
\end{split}
\end{align}

Setzt man wieder den oszillatorischen Produktansatz
\[ u_k(n, i, t_n, x_i) = w_k(t_n, x_i) + (-1)^i \Omega(n) z_k(t_n, x_i), \qquad k = 0,1,2 \]
ein, so folgt aus \eqref{eq:transport:kleineta:o1}
\[ (-1)^i z_0(t_n, x_i) \bigl( \Omega(n+1) + \Omega(n) \bigr) = 0, \]
und das impliziert ganz analog wie in Satz \ref{satz:omega_n}, dass $\Omega(n) = (-1)^n$ gilt.
Folglich ist unser Ansatz durch
\begin{align}
v^n_i = \begin{split}
&w_0(t_n, x_i) + h w_1(t_n, x_i) + h^2 w_2(t_n, x_i)\\
&\qquad + (-1)^{i+n} \bigl( z_0(t_n, x_i) + h z_1(t_n, x_i) + h^2 z_2(t_n, x_i) \bigr)
\end{split}
\end{align}
gegeben. Hieraus folgen dieses mal die Gleichungen:

\vspace{0.4cm}
\noindent \emph{In der Ordnung $O(h)$}
\begin{align*}
\partial_t w_0(t, x) + \partial_x w_0(t, x) &= 0 \qquad \text{und}\\
\partial_t z_0(t, x) + \partial_x z_0(t, x) &= 2 z_0(t, x)
\end{align*}
woraus Wegen der Anfangsbedingungen \eqref{eq:transport:kleineta:anfangsbedinungen} $w_0(t,x) = U(x -t)$ und $z_0(t,x) = V(x - t) e^{2 t}$ folgt.

\begin{figure}
\centering
\begin{tikzpicture}
\begin{semilogyaxis}[
    title={$\err^n = \max_{i \in \Z} \abs{\sin\bigl(\pi (x_i - t_n )\bigr) - v^n_i}$},
    xlabel={Zeit $t$},
    ylabel={maximaler Fehler},
    legend entries={$\err^n$,$\eps_M e^{2t}$, $t h^2 \frac{\pi^2}{2}$, $\eps_M e^{2t} + t h^2 \frac{\pi^2}{2}$},
    legend style={at={(1.5,1)}}
]
\addplot[myblue, line width={2}] table {data/max_errors_eta_0.001_h_0.001.dat};
\addplot[black, line width={0.5}, dotted] table [y index={2}] {data/max_errors_eta_0.001_h_0.001.dat};
\addplot[mygray, line width={1}, dashdotted] table [y index={4}] {data/max_errors_eta_0.001_h_0.001.dat};
\addplot[black, line width={0.5}, mark=o, mark repeat={10}] table [y index={3}] {data/max_errors_eta_0.001_h_0.001.dat};
\end{semilogyaxis}
\end{tikzpicture}
\caption{Hier vergleichen wir die maximalen Fehler der numerischen Lösungen für die Startwerte $U(x) = sin(\pi x)$, $V(x) = \eps_M$ und $\eta = h = 10^{-3}$ zur echten Lösung $u(t,x) = sin(\pi(x - t))$ mit dem geschätztem Fehler $\eps_M e^{2t}$ aus der asymptotischen Entwicklung in \eqref{eq:transport:kleineta:loesung}.}
\label{fig:transport:kleineta:max_error}
\end{figure}

\vspace{0.4cm}
\noindent \emph{In der Ordnung $O(h^2)$}
\begin{align*}
\partial_t w_1(t, x) + \partial_x w_1(t, x) &= 0 \qquad \text{und}\\
\partial_t z_1(t, x) + \partial_x z_1(t, x) &= 2 z_1(t, x).
\end{align*}
Dieses mal folgt aus $w_1(0,x) = z_1(0,x) = 0$ sogar $z_1 = w_1 = 0$.

\vspace{0.4cm}
\noindent \emph{In der Ordnung $O(h^3)$}
\begin{align*}
\partial_t w_2(t, x) + \partial_x w_2(t, x) &= - \frac{1}{2} \partial^2_x w_0(t, x) \qquad \text{und}\\
\partial_t z_2(t, x) + \partial_x z_2(t, x) &= \frac{1}{2} \partial^2_x z_0(t, x) - \partial^2_t z_0(t, x) + 2 z_2(t, x)\\
&= \frac{1}{2} \partial^2_x z_0(t, x) - \partial_t \bigl( z_0(t, x) - \partial_x z_0 \bigr) + 2 z_2(t, x)\\
&= \frac{1}{2} \partial^2_x z_0(t, x) + \partial_x z_0(t, x) - z_0(t, x) + \partial_x \bigl( z_0 - \partial_x z_0 \bigr) + 2 z_2(t, x)\\
&= - \frac{1}{2} \partial^2_x z_0(t, x) + 2 \partial_x z_0(t, x) - z_0(t, x) + 2 z_2(t, x)\\
\end{align*}

Um die Differentialgleichung für $z_2$ zu lösen, machen wir den Ansatz

\[ z(t,x) = e^{2t} A(t,x). \]

Dann gilt

\begin{align*}
\partial_x z(t,x) &= e^{2t} \partial_x A(t,x)\\
\partial_t z(t,x) &= 2 e^{2t} A(t,x) + e^{2t} \partial_t A(t, x)\\
                  &= 2 z(t, x) + e^{2t} \partial_t A(t, x).
\end{align*}

Wenn also
\[ \partial_t z(t, x) + \partial_x z(t, x) = - \frac{1}{2} \partial^2_x z_0(t, x) + 2 \partial_x z_0(t, x) - z_0(t, x) + 2 z(t, x) \]
gelten soll, so müssen wir $A$ derart bestimmen, so dass
\[ \partial_t A(t, x) + \partial_x A(t,x) = e^{-2t} \bigl( - \frac{1}{2} \partial^2_x z_0(t, x) + 2 \partial_x z_0(t, x) - z_0(t, x) \bigr) \]
gilt. Da nun $z_0(t,x) = e^{2t} V(x - t)$ gilt, folgt
\[ \partial_t A(t, x) + \partial_x A(t,x) = - \frac{1}{2} \partial^2_x V(x - t) + 2 \partial_x V(x - t) - V(x - t) \]
und das ist die inhomogene Transportgleichung für $A$. Somit ist die Lösung durch
\[ A(t,x) = t \left( - \frac{1}{2} \partial^2_x V(x - t) + 2 \partial_x V(x - t) - V(x - t) \right) \]
gegeben und es gilt insgesamt
\[ z(t,x) = t e^{2t} \left( - \frac{1}{2} \partial^2_x V(x - t) + 2 \partial_x V(x - t) - V(x - t) \right) \]

\begin{align*}
w_2(t,x) &= - t \frac{1}{2} \partial^2_x U(x - t) \qquad \text{und}\\
z_2(t,x) &= t e^{2t} \left( - \frac{1}{2} \partial^2_x V(x - t) + 2 \partial_x V(x - t) - V(x - t) \right)\\
\end{align*}

Denn es gilt 

\begin{align*}
\partial_t z_2(t,x) &= \partial_t \left( e^{2t} \int_0^t e^{-2s} \left[ - \frac{1}{2} \partial^2_x z_0(s, x) + 2 \partial_x z_0(s, x) - z_0(s,x) \right] \dd s \right)\\
&= 2 z_2(t,x) + e^{2t} e^{-2t} \left[ - \frac{1}{2} \partial^2_x z_0(t, x) + 2 \partial_x z_0(t, x) - z_0(t,x) \right]\\
&= 2 z_2(t,x) - \frac{1}{2} \partial^2_x z_0(t, x) + 2 \partial_x z_0(t, x) - z_0(t,x)
\end{align*}

\section{Andere Frequenzen auf Gitterniveau -- ein Exponentialansatz}